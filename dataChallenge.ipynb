{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44264ed1-44ab-4ab3-a408-af3c643fc908",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vischia/lisbon-ml-school/blob/master/dataChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8d289-3918-452e-b6e1-28ed97caa8e4",
   "metadata": {},
   "source": [
    "# Lisbon Machine Learning School\n",
    "## Data Challenge!!! Multitarget regression\n",
    "\n",
    "(C) Pietro Vischia (Universidad de Oviedo and ICTEA), pietro.vischia@cern.ch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d49ac6-f688-46d1-82bb-c93ef1eb2cb6",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "\n",
    "- If you are running locally, you don't need to run anything\n",
    "\n",
    "- If you are running on Google Colab, uncomment and run the next cell (remove only the \"#\", keep the \"!\"). You can also run it from a local installation, but it will do nothing if you have already installed all dependencies (and it will take some time to tell you it is not gonna do anything)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9fe7a-5c11-4ce6-be45-402a10f052a0",
   "metadata": {},
   "source": [
    "## Load the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c894a5d9-5ab1-442b-af11-13bcf3f79f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch version 2.6.0\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "import torchinfo\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "\n",
    "import uproot\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8, 6)\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "\n",
    "print('Using torch version', torch.__version__)\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b52b21-e0e5-4c2a-9afb-e42afb99e42f",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6cf761-a0b2-496c-83bc-5344dca6902d",
   "metadata": {},
   "source": [
    "We will use the same data we used for exercise 2, that is simulated events corresponding to three physics processes.\n",
    "- ttH production\n",
    "- ttW production\n",
    "- Drell-Yan ($pp\\\\to Z/\\\\gamma^*$+jets) production\n",
    "\n",
    "We will select the multilepton final state, which is a challenging final state with a rich structure and nontrivial background separation.\n",
    "\n",
    "<img src=\"figs/2lss.png\" alt=\"ttH multilepton 2lss\" style=\"width:40%\"/>\n",
    "\n",
    "We use the [uproot](https://uproot.readthedocs.io/en/latest/basic.html) library to conveniently read in a [ROOT TNuple](https://root.cern.ch/doc/master/classTNtuple.html) which can automatically convert it to a [pandas dataframe](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "74a60566-fd81-4c4b-b80c-1dafc8dc60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download the data only if you haven't done so yet\n",
    "\n",
    "# if not os.path.isfile(\"data/signal_blind20.root\"): \n",
    "#     !mkdir data; cd data/; wget https://www.hep.uniovi.es/vischia/lisbon_ml_school/lisbon_ml_school_tth.tar.gz; tar xzvf lisbon_ml_school_tth.tar.gz; rm lisbon_ml_school_tth.tar.gz; cd -;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c829b510-e956-477d-a841-81b0a369ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = uproot.open('data/signal_blind20.root')['Friends'].arrays(library=\"pd\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc7ae9-0d8e-4dac-b3bc-b8e986eb1654",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "Select the features you want to use for this exercise, don't forget to remove unnecessary features.\n",
    "\n",
    "Most of the variables are input features, corresponding to detector measurements of the properties of the reconstructed decay products.\n",
    "\n",
    "There are three special variables, though:\n",
    "\n",
    "- `Hreco_evt_tag`: this feature has values in ${0,1}$, where $1$ flags the event as signal event, and $0$ flags the event as background event;\n",
    "- `Hreco_HTXS_Higgs_pt`: this feature contains the true generate Higgs boson transverse momentum at generator level (used for regression);\n",
    "- `Hreco_HTXS_Higgs_y`: this feature contains the true generated Higgs boson rapidity (not pseudorapidity) at generator level (used for regression).\n",
    "\n",
    "\n",
    "### Important\n",
    "\n",
    "Twenty percent of the events have `-99` in the `Hreco_HTXS_Higgs_pt` and `Hreco_HTXS_Higgs_y` values. These are the \"unlabelled\" events that you will have to send predictions for. You should filter them out for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dec0a6-c8da-4201-b7a9-675be0612864",
   "metadata": {},
   "source": [
    "## The assignment\n",
    "\n",
    "- For this data challenge, your target is to simultaneously regress the Higgs transverse momentum `Hreco_HTXS_Higgs_pt` and the rapidity `Hreco_HTXS_Higgs_y`\n",
    "\n",
    "- You will need to split your dataset into two parts: one is where you have access to the pT and y labels (80% of the dataset): you will build your training and test sets from this. The other is where the pT and y has been set to -99: this is the portion of data that is kept blind. You will have to use 80% of the data to train a regressor, then evaluate the output of your regressor on the blind 20% of the data, and send us the results. We will compare the result with the true value we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "406b6ce3-0f17-4d42-a581-1ad77a019490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19994854437379506\n",
      "0.31147360226137455\n",
      "Index(['Hreco_Lep0_pt', 'Hreco_Lep1_pt', 'Hreco_HadTop_pt',\n",
      "       'Hreco_All5_Jets_pt', 'Hreco_More5_Jets_pt', 'Hreco_Jets_plus_Lep_pt',\n",
      "       'Hreco_Lep0_eta', 'Hreco_Lep1_eta', 'Hreco_HadTop_eta',\n",
      "       'Hreco_All5_Jets_eta', 'Hreco_More5_Jets_eta',\n",
      "       'Hreco_Jets_plus_Lep_eta', 'Hreco_Lep0_phi', 'Hreco_Lep1_phi',\n",
      "       'Hreco_HadTop_phi', 'Hreco_All5_Jets_phi', 'Hreco_More5_Jets_phi',\n",
      "       'Hreco_Jets_plus_Lep_phi', 'Hreco_Lep0_mass', 'Hreco_Lep1_mass',\n",
      "       'Hreco_HadTop_mass', 'Hreco_All5_Jets_mass', 'Hreco_More5_Jets_mass',\n",
      "       'Hreco_Jets_plus_Lep_mass', 'Hreco_TopScore', 'Hreco_met',\n",
      "       'Hreco_met_phi'],\n",
      "      dtype='object')\n",
      "Index(['Hreco_HTXS_Higgs_pt', 'Hreco_HTXS_Higgs_y'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop unneeded features\n",
    "\n",
    "blind_data = data[data[\"Hreco_HTXS_Higgs_pt\"]==-99]\n",
    "\n",
    "train_val_data = data[data[\"Hreco_HTXS_Higgs_pt\"]!=-99]\n",
    "train_val_data = data[data[\"Hreco_Lep2_pt\"]!=-99]\n",
    "\n",
    "print(blind_data.shape[0] / data.shape[0])\n",
    "print(train_val_data.shape[0] / data.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "train_val_labels = train_val_data[[\"Hreco_HTXS_Higgs_pt\", \"Hreco_HTXS_Higgs_y\"]].copy()\n",
    "\n",
    "train_val_data = train_val_data.drop([\"index\", \"Hreco_HTXS_Higgs_pt\", \"Hreco_Lep2_phi\", \"Hreco_Lep2_mass\", \"Hreco_Lep2_eta\", \"Hreco_Lep2_pt\" , \"Hreco_HTXS_Higgs_y\", \"Hreco_evt_tag\"], axis=1 )\n",
    "\n",
    "# Filter data\n",
    "print(train_val_data.columns)\n",
    "print(train_val_labels.columns)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler# standard scaling\n",
    "train_data, val_data, train_labels, val_labels = sklearn.model_selection.train_test_split(train_val_data, train_val_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Scale the train input features\n",
    "for column in train_data.columns:\n",
    "    scaler_train = StandardScaler().fit(train_data.filter([column], axis=1))\n",
    "    train_data[column] = scaler_train.transform(train_data.filter([column], axis=1))\n",
    "\n",
    "for column in val_data.columns:\n",
    "    scaler_val = StandardScaler().fit(val_data.filter([column], axis=1))\n",
    "    val_data[column] = scaler_val.transform(val_data.filter([column], axis=1))\n",
    "\n",
    "\n",
    "# Scale the labels\n",
    "for column in train_labels.columns:\n",
    "    scaler_train_label = StandardScaler().fit(train_labels.filter([column], axis=1))\n",
    "    train_labels[column] = scaler_train_label.transform(train_labels.filter([column], axis=1))\n",
    "\n",
    "for column in val_labels.columns:\n",
    "    scaler_val_label = StandardScaler().fit(val_labels.filter([column], axis=1))\n",
    "    val_labels[column] = scaler_val_label.transform(val_labels.filter([column], axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a72e29-98fb-41ac-b178-30402b03968a",
   "metadata": {},
   "source": [
    "- The loss function typically used for regression problems is the mean square error: in this case you will have to figure out how to deal with the fact that the output vector has dimension two (transverse momentum, and rapidity).\n",
    "- A tricky challenge is to deal with output features that have different scales: the rapidity is of $\\mathcal{O}(1)$, the transverse momentum is of $\\\\mathcal{O}(100-1000}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772d79b-6dcd-4a2b-b9c1-5fb5b204771c",
   "metadata": {},
   "source": [
    "## Regression problems\n",
    "\n",
    "Regression problems require the prediction to be free of adopting the same range as the target variable(s) that need to be regressed.\n",
    "\n",
    "This is why the sigmoid activation function is not a good choice. The typical form of output layers of a regression problem is, if `n_outputs` is the dimension of the output vector:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1376288d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1024, 27])\n",
      "Labels batch shape: torch.Size([1024, 2])\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, device=torch.device(\"cpu\")):\n",
    "        self.X = torch.Tensor(X.values).to(device)\n",
    "        self.y = torch.Tensor(y.values).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        datum = self.X[idx]\n",
    "        \n",
    "        return datum, label\n",
    "\n",
    "batch_size=1024 # Minibatch learning\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(train_data, train_labels)\n",
    "val_dataset = MyDataset(val_data, val_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "78cbe240-aa59-40ce-9878-0877f6366a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=27, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Linear(in_features=64, out_features=8, bias=True)\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Now let's see some more detailed info by using the torchinfo package\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork                            [1024, 2]                 --\n",
       "├─Sequential: 1-1                        [1024, 2]                 --\n",
       "│    └─Linear: 2-1                       [1024, 1024]              28,672\n",
       "│    └─LeakyReLU: 2-2                    [1024, 1024]              --\n",
       "│    └─Linear: 2-3                       [1024, 512]               524,800\n",
       "│    └─LeakyReLU: 2-4                    [1024, 512]               --\n",
       "│    └─Linear: 2-5                       [1024, 128]               65,664\n",
       "│    └─LeakyReLU: 2-6                    [1024, 128]               --\n",
       "│    └─Linear: 2-7                       [1024, 64]                8,256\n",
       "│    └─LeakyReLU: 2-8                    [1024, 64]                --\n",
       "│    └─Linear: 2-9                       [1024, 8]                 520\n",
       "│    └─LeakyReLU: 2-10                   [1024, 8]                 --\n",
       "│    └─Linear: 2-11                      [1024, 2]                 18\n",
       "==========================================================================================\n",
       "Total params: 627,930\n",
       "Trainable params: 627,930\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 643.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 14.24\n",
       "Params size (MB): 2.51\n",
       "Estimated Total Size (MB): 16.86\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, ninputs, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(ninputs, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(8, 2),\n",
    "        )\n",
    "        self.linear_relu_stack.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass data through conv1\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork(train_data.shape[1])\n",
    "\n",
    "print(model) # some basic info\n",
    "\n",
    "print(\"Now let's see some more detailed info by using the torchinfo package\")\n",
    "torchinfo.summary(model, input_size=(batch_size, train_data.shape[1])) # the input size is (batch size, number of features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314e71e-c8f2-41ce-8107-370ed15f64fd",
   "metadata": {},
   "source": [
    "The other big change with respect to classification models is that the cross-entropy is not the proper loss function anymore.\n",
    "\n",
    "The regression problem is essentially a generalization of a linear regression problem, and the typical error estimates from classical statistics apply, each with its pros and cons.\n",
    "\n",
    "#### Mean Absolute Error (MAE)\n",
    "\n",
    "$MAE(\\hat{y}, y^{*}) = \\frac{1}{N} \\sum |\\hat{y} - y^{*}|$\n",
    "\n",
    "- Lower values are better.\n",
    "- It estimates the average error, thus cannot distinguish between one large error and many small errors.\n",
    "\n",
    "#### Root Mean Squared Error (RMSE)\n",
    "\n",
    "$RMSE(\\hat{y}, y^{*}) = \\sqrt{\\sum \\frac{(\\hat{y} - y^{*})^2}{N}}$\n",
    "\n",
    "- Lower values are better.\n",
    "- It estimates the spread of the residuals (standard deviation of the unexplained variance)\n",
    "- It gives large weight to large errors (if you use it as loss function, it will prioritize the reduction of large errors)\n",
    "\n",
    "#### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "$MAPE(\\hat{y}, y^{*}) = \\frac{100\\%}{N} \\sum \\Big|\\frac{\\hat{y} - y^{*}}{y^{*}}\\Big|$\n",
    "\n",
    "#### R-Squared Score\n",
    "\n",
    "$R^2(\\hat{y}, y^{*}) = 1-\\frac{ \\sum (\\hat{y} - y^{*})^2}{  \\sum(\\bar{y} - y^{*})^2  }$, \n",
    "\n",
    "where $\\bar{y}$ is the arithmetic mean of the true values, $\\bar{y} = \\frac{1}{N}\\sum_{i=0}^{N-1} y^{*}$\n",
    "\n",
    "- It estimates how well the model explains the variance of the data\n",
    "- It can be negative (and that means that the model fits badly the data)\n",
    "\n",
    "\n",
    "You can consult online [an overview of the available loss functions in `pytorch`](https://pytorch.org/docs/stable/nn.html#loss-functions).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd38be-7db1-4950-a55e-f1c17a0da3fd",
   "metadata": {},
   "source": [
    "## A few hints\n",
    "\n",
    "- Remove useless features\n",
    "- Consider the possibility of applying preprocessing to the input features, to the target features, or to both\n",
    "- Choose the appropriate metric to track\n",
    "- You can recycle the code for DataSet, DataLoader, Neural Network model, and train/test loops from exercise_1 essentially verbatim. Just make sure you change the loss function, and you change the output activation function to `nnReLU()`\n",
    "- Loss functions can be made as complicated as you want by defining your own loss function, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e77bdd1e-12d3-497f-bb5a-89402cd869c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef484b5-fd1d-41e7-b060-1ff4f2c35f15",
   "metadata": {},
   "source": [
    "## The scoring system\n",
    "\n",
    "- You will have to define a model with two output nodes: the first one must regress the Higgs boson transverse momentum, the second one must regress the Higgs boson rapidity.\n",
    "- You can also use any flavour of boosted decision trees you may see fit, but implemented in `torch`.\n",
    "- You will have to evaluate your model on the unlabelled data, save the predictions to a csv file with commas as separators (format: pt, y), and send us the csv file (see below). \n",
    "- If you have filtered the features further, please include in the email the code that creates the `data` dataframe.\n",
    "\n",
    "We will evaluate the results of the challenge on the unlabelled events, using as performance metric the RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "41f61a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, scheduler, best_model_path, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    losses=[] # Track the loss function\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    #for batch, (X, y) in enumerate(dataloader):\n",
    "    best_loss = np.inf\n",
    "    for (X,y) in tqdm(dataloader):\n",
    "        # Reset gradients (to avoid their accumulation)\n",
    "        optimizer.zero_grad()\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        #if (all_equal3(pred.detach().numpy())):\n",
    "        #    print(\"All equal!\")\n",
    "        loss = loss_fn(pred.squeeze(dim=1), y)\n",
    "        losses.append(loss.detach().cpu())\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss.detach().cpu()\n",
    "            torch.save(model.state_dict(), best_model_path) # Save the full state of the model, to have access to the training history\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e239037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    losses=[] # Track the loss function\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        #for X, y in dataloader:\n",
    "        for (X,y) in tqdm(dataloader):\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred.squeeze(dim=1), y).item()\n",
    "            losses.append(loss)\n",
    "            test_loss += loss\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ea4ff88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.68it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 130.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9434934 , Avg test loss 0.9442650258541108 Current learning rate [0.001]\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 153.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9325374 , Avg test loss 0.9349767446517945 Current learning rate [0.001]\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 48.31it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 131.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9314338 , Avg test loss 0.936562567949295 Current learning rate [0.001]\n",
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 129.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.93143 , Avg test loss 0.9356778562068939 Current learning rate [0.001]\n",
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 41.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 94.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.92928964 , Avg test loss 0.9220294296741486 Current learning rate [0.001]\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 143.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.92820156 , Avg test loss 0.9391980767250061 Current learning rate [0.001]\n",
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 141.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.926116 , Avg test loss 0.9282668590545654 Current learning rate [0.001]\n",
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 49.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 139.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9246158 , Avg test loss 0.9257114589214325 Current learning rate [0.001]\n",
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.17it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 140.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.92386 , Avg test loss 0.9341642677783966 Current learning rate [0.001]\n",
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 129.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9225251 , Avg test loss 0.9329204022884369 Current learning rate [0.001]\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.61it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 128.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9197316 , Avg test loss 0.9488573014736176 Current learning rate [0.001]\n",
      "Epoch 12\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 136.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.91803855 , Avg test loss 0.9508705496788025 Current learning rate [0.001]\n",
      "Epoch 13\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.80it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 132.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.91731894 , Avg test loss 0.9345080316066742 Current learning rate [0.001]\n",
      "Epoch 14\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.26it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 126.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9122205 , Avg test loss 0.945417869091034 Current learning rate [0.001]\n",
      "Epoch 15\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 41.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 135.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9092792 , Avg test loss 0.9348316133022309 Current learning rate [0.001]\n",
      "Epoch 16\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 139.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.90714794 , Avg test loss 0.9421022593975067 Current learning rate [0.001]\n",
      "Epoch 17\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.50it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 131.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.9024509 , Avg test loss 0.9571238458156586 Current learning rate [0.001]\n",
      "Epoch 18\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 138.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.89575845 , Avg test loss 0.978283554315567 Current learning rate [0.001]\n",
      "Epoch 19\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 138.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.89004683 , Avg test loss 0.9749156415462494 Current learning rate [0.001]\n",
      "Epoch 20\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.03it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 139.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.88180774 , Avg test loss 0.9736307501792908 Current learning rate [0.001]\n",
      "Epoch 21\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 130.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.87413293 , Avg test loss 0.9953258335590363 Current learning rate [0.001]\n",
      "Epoch 22\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.82it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 131.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.8616897 , Avg test loss 0.9897494375705719 Current learning rate [0.001]\n",
      "Epoch 23\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 54.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.8503322 , Avg test loss 0.9913139700889587 Current learning rate [0.001]\n",
      "Epoch 24\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 130.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.8363067 , Avg test loss 1.0282044291496277 Current learning rate [0.001]\n",
      "Epoch 25\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.06it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 137.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.8271664 , Avg test loss 1.0067575573921204 Current learning rate [0.001]\n",
      "Epoch 26\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 135.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.8110372 , Avg test loss 1.011335551738739 Current learning rate [0.001]\n",
      "Epoch 27\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.60it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 135.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.78679526 , Avg test loss 1.0236418306827546 Current learning rate [0.001]\n",
      "Epoch 28\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 53.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.7742043 , Avg test loss 1.0277492880821228 Current learning rate [0.001]\n",
      "Epoch 29\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 138.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.7531849 , Avg test loss 1.0885647892951966 Current learning rate [0.001]\n",
      "Epoch 30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 41.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 139.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.73099613 , Avg test loss 1.0936519265174867 Current learning rate [0.001]\n",
      "Epoch 31\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 48.99it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 117.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.71000814 , Avg test loss 1.0612427711486816 Current learning rate [0.001]\n",
      "Epoch 32\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 143.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.6935171 , Avg test loss 1.096023792028427 Current learning rate [0.001]\n",
      "Epoch 33\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.13it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 146.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.66657907 , Avg test loss 1.1180036783218383 Current learning rate [0.001]\n",
      "Epoch 34\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 51.27it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 142.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.6468285 , Avg test loss 1.0947550535202026 Current learning rate [0.001]\n",
      "Epoch 35\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.55it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 143.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.6205283 , Avg test loss 1.1618257403373717 Current learning rate [0.001]\n",
      "Epoch 36\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 49.40it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 129.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.6002222 , Avg test loss 1.1719868183135986 Current learning rate [0.001]\n",
      "Epoch 37\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 141.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.5769935 , Avg test loss 1.1434903681278228 Current learning rate [0.001]\n",
      "Epoch 38\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.73it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 145.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.55138254 , Avg test loss 1.1758246421813965 Current learning rate [0.001]\n",
      "Epoch 39\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 49.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 144.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.5353158 , Avg test loss 1.2286362051963806 Current learning rate [0.001]\n",
      "Epoch 40\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 48.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 149.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.5106465 , Avg test loss 1.2666489601135253 Current learning rate [0.001]\n",
      "Epoch 41\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 51.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 145.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.496232 , Avg test loss 1.2604601740837098 Current learning rate [0.001]\n",
      "Epoch 42\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.94it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 84.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.4795912 , Avg test loss 1.2464083075523376 Current learning rate [0.001]\n",
      "Epoch 43\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 48.03it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 143.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.46313593 , Avg test loss 1.3116262793540954 Current learning rate [0.001]\n",
      "Epoch 44\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 51.37it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 143.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.43938503 , Avg test loss 1.3367955803871154 Current learning rate [0.001]\n",
      "Epoch 45\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.99it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 143.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.42847386 , Avg test loss 1.3059293031692505 Current learning rate [0.001]\n",
      "Epoch 46\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 143.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.42176783 , Avg test loss 1.2895669341087341 Current learning rate [0.001]\n",
      "Epoch 47\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 48.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 145.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.40558773 , Avg test loss 1.3254153609275818 Current learning rate [0.001]\n",
      "Epoch 48\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.96it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 142.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.38502392 , Avg test loss 1.3333924770355225 Current learning rate [0.001]\n",
      "Epoch 49\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 117.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.36968586 , Avg test loss 1.3607221961021423 Current learning rate [0.001]\n",
      "Epoch 50\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 126.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.36184728 , Avg test loss 1.3803314924240113 Current learning rate [0.001]\n",
      "Epoch 51\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 132.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.346057 , Avg test loss 1.3253016471862793 Current learning rate [0.001]\n",
      "Epoch 52\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 124.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.33343327 , Avg test loss 1.3212468862533568 Current learning rate [0.001]\n",
      "Epoch 53\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 127.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.33449063 , Avg test loss 1.3627800941467285 Current learning rate [0.001]\n",
      "Epoch 54\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 131.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.32786983 , Avg test loss 1.3595868825912476 Current learning rate [0.001]\n",
      "Epoch 55\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.79it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 134.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.32084852 , Avg test loss 1.3138784289360046 Current learning rate [0.001]\n",
      "Epoch 56\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 48.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 55.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.31386784 , Avg test loss 1.3853513836860656 Current learning rate [0.001]\n",
      "Epoch 57\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 48.50it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 134.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.3018418 , Avg test loss 1.3869854092597962 Current learning rate [0.001]\n",
      "Epoch 58\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 132.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.28874066 , Avg test loss 1.4043187379837037 Current learning rate [0.001]\n",
      "Epoch 59\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 50.27it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 132.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.2837748 , Avg test loss 1.3234240055084228 Current learning rate [0.001]\n",
      "Epoch 60\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.35it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 135.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.26517823 , Avg test loss 1.3938623666763306 Current learning rate [0.001]\n",
      "Epoch 61\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 126.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.25892997 , Avg test loss 1.4270376086235046 Current learning rate [0.001]\n",
      "Epoch 62\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 47.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 126.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.26235119 , Avg test loss 1.4638028502464295 Current learning rate [0.001]\n",
      "Epoch 63\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.68it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 135.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.2456461 , Avg test loss 1.470840585231781 Current learning rate [0.001]\n",
      "Epoch 64\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.87it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 125.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.24503133 , Avg test loss 1.384425127506256 Current learning rate [0.001]\n",
      "Epoch 65\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 123.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.25407603 , Avg test loss 1.4254969716072083 Current learning rate [0.001]\n",
      "Epoch 66\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.98it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 121.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.24831972 , Avg test loss 1.4079814434051514 Current learning rate [0.001]\n",
      "Epoch 67\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 42.19it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 124.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.24112324 , Avg test loss 1.427822768688202 Current learning rate [0.001]\n",
      "Epoch 68\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 107.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.2307276 , Avg test loss 1.4094164729118348 Current learning rate [0.001]\n",
      "Epoch 69\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.19it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 115.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.22945528 , Avg test loss 1.4122047662734984 Current learning rate [0.001]\n",
      "Epoch 70\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:02<00:00, 40.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 123.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.22950736 , Avg test loss 1.416962194442749 Current learning rate [0.001]\n",
      "Epoch 71\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 120.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.22096062 , Avg test loss 1.4160566806793213 Current learning rate [0.001]\n",
      "Epoch 72\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 42.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 50.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.21707714 , Avg test loss 1.4629947662353515 Current learning rate [0.001]\n",
      "Epoch 73\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.10it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 123.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.21434912 , Avg test loss 1.3966676831245421 Current learning rate [0.001]\n",
      "Epoch 74\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:02<00:00, 39.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 110.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.2108117 , Avg test loss 1.4618424892425537 Current learning rate [0.001]\n",
      "Epoch 75\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 41.85it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 119.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.21428551 , Avg test loss 1.4150670647621155 Current learning rate [0.001]\n",
      "Epoch 76\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:02<00:00, 40.49it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 109.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.21466918 , Avg test loss 1.4640097498893738 Current learning rate [0.001]\n",
      "Epoch 77\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 42.41it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 121.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.20490544 , Avg test loss 1.4493626594543456 Current learning rate [0.001]\n",
      "Epoch 78\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 121.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.1998228 , Avg test loss 1.4278116464614867 Current learning rate [0.001]\n",
      "Epoch 79\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 42.04it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 120.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.20190367 , Avg test loss 1.4544457912445068 Current learning rate [0.001]\n",
      "Epoch 80\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.55it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 121.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.1972692 , Avg test loss 1.4687299013137818 Current learning rate [0.001]\n",
      "Epoch 81\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 77.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.1946166 , Avg test loss 1.5354082465171814 Current learning rate [0.001]\n",
      "Epoch 82\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 41.79it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 128.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.19032519 , Avg test loss 1.437081754207611 Current learning rate [0.001]\n",
      "Epoch 83\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 122.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.18675402 , Avg test loss 1.4089641928672791 Current learning rate [0.001]\n",
      "Epoch 84\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 41.62it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 72.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.1984411 , Avg test loss 1.4455866694450379 Current learning rate [0.001]\n",
      "Epoch 85\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.05it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 127.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.2020697 , Avg test loss 1.4622165203094482 Current learning rate [0.001]\n",
      "Epoch 86\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.83it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 132.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.1952753 , Avg test loss 1.4395705819129945 Current learning rate [0.001]\n",
      "Epoch 87\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.03it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 134.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.18954904 , Avg test loss 1.5176151514053344 Current learning rate [0.001]\n",
      "Epoch 88\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 46.07it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 134.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.18115975 , Avg test loss 1.444703722000122 Current learning rate [0.001]\n",
      "Epoch 89\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 125.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.17213723 , Avg test loss 1.5253793120384216 Current learning rate [0.001]\n",
      "Epoch 90\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.40it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 132.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.16742894 , Avg test loss 1.4607688188552856 Current learning rate [0.001]\n",
      "Epoch 91\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 42.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 128.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.15978986 , Avg test loss 1.5215546250343324 Current learning rate [0.001]\n",
      "Epoch 92\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.13it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 116.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.15120429 , Avg test loss 1.4598183035850525 Current learning rate [0.001]\n",
      "Epoch 93\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.21it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 98.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.15457538 , Avg test loss 1.4615948677062989 Current learning rate [0.001]\n",
      "Epoch 94\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 129.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.16022037 , Avg test loss 1.4331751704216003 Current learning rate [0.001]\n",
      "Epoch 95\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 52.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.16485523 , Avg test loss 1.4849838256835937 Current learning rate [0.001]\n",
      "Epoch 96\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 125.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.17768343 , Avg test loss 1.4714834690093994 Current learning rate [0.001]\n",
      "Epoch 97\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 127.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.18184341 , Avg test loss 1.4916255354881287 Current learning rate [0.001]\n",
      "Epoch 98\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 44.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 124.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.17776029 , Avg test loss 1.5163852095603942 Current learning rate [0.001]\n",
      "Epoch 99\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 43.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 125.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.18081097 , Avg test loss 1.5252744436264039 Current learning rate [0.001]\n",
      "Epoch 100\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:01<00:00, 45.03it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 53.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss 0.16829267 , Avg test loss 1.4610125780105592 Current learning rate [0.0009000000000000001]\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "learningRate = 0.001\n",
    "\n",
    "# The optimizer decides which path to follow through the gradient of the loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "# The scheduler reduces the learning rate for the optimizer in order to for the optimizer to be able to \"enter\" narrow minima\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 100, gamma=0.9)\n",
    "\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "best_model_path = \"best_dnn_model.h5\"\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss=train_loop(train_dataloader, model, loss_fn, optimizer, scheduler, best_model_path, device)\n",
    "    test_loss=test_loop(test_dataloader, model, loss_fn, device)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    # print(\"Avg train loss\", train_loss, \", Current learning rate\", scheduler.get_last_lr())\n",
    "    print(\"Avg train loss\", train_loss, \", Avg test loss\", test_loss, \"Current learning rate\", scheduler.get_last_lr())\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "381af134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Average training loss\")\n",
    "plt.plot(test_losses, label=\"Average test loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bcbc4170-4898-477f-acab-125aecbb9da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blind_data_X_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m to_send \u001b[38;5;241m=\u001b[39m model(\u001b[43mblind_data_X_features\u001b[49m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      3\u001b[0m df_to_send \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(to_send)\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_file_group_N\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# Replace \"N\" with the group number we assigned you\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blind_data_X_features' is not defined"
     ]
    }
   ],
   "source": [
    "to_send = model(blind_data_X_features).cpu().numpy()\n",
    "\n",
    "df_to_send = pd.DataFrame(to_send)\n",
    "df.to_csv(\"my_file_group_N\",index=False) # Replace \"N\" with the group number we assigned you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22ec80-956b-45ab-9e0d-58325019a516",
   "metadata": {},
   "source": [
    "# Practical instructions\n",
    "\n",
    "- Divide yourselves in groups of three. Once the groups are defined, we will assign you a numerical label.\n",
    "- Each group will have to send the csv file mentioned above as an attached `.csv`file to [lisbon-ml-workshop@cern.ch](mailto:lisbon-ml-workshop@cern.ch). The email (ONE EMAIL PER GROUP) must have:\n",
    "  - As an object: \"LIP ML Workshop Data Challenge: Group N\", where \"N\" is the number we assigned you above\n",
    "  - All the three members of the group must be in carbon copy to the email\n",
    "  - In the email text there must be a list of the full names of the three members of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e742f57-0770-4043-b0e0-b50441146557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lisbon_ml_school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
